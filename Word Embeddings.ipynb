{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency-based Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vector Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### references\n",
    "\n",
    "[How areTF-IDF calculated by the scikit-learn TfidfVectorizer](https://stackoverflow.com/questions/36966019/how-aretf-idf-calculated-by-the-scikit-learn-tfidfvectorizer)\n",
    "\n",
    "TF-IDF is done in multiple steps by Scikit Learn's __TfidfVectorizer__, which in fact __uses TfidfTransformer__ and __inherits CountVectorizer__.\n",
    "\n",
    "Let me summarize the steps it does to make it more straightforward:\n",
    "\n",
    "- tfs are calculated by __CountVectorizer's fit_transform()__\n",
    "- idfs are calculated by __TfidfTransformer's fit()__\n",
    "- tfidfs are calculated by __TfidfTransformer's transform()__\n",
    "\n",
    "[How to Use Tfidftransformer & Tfidfvectorizer?](https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.XkJQm1IzZTY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### term frequencies using CountVectorizer's fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 14, 'house': 7, 'had': 6, 'tiny': 15, 'little': 8, 'mouse': 9, 'cat': 2, 'saw': 12, 'ran': 11, 'away': 1, 'from': 5, 'finally': 4, 'ate': 0, 'end': 3, 'of': 10, 'story': 13}\n",
      "['ate', 'away', 'cat', 'end', 'finally', 'from', 'had', 'house', 'little', 'mouse', 'of', 'ran', 'saw', 'story', 'the', 'tiny']\n",
      "[[0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 1 0 2 0]\n",
      " [0 1 0 0 0 1 0 1 0 1 0 1 0 0 2 0]\n",
      " [1 0 1 0 1 0 0 0 0 1 0 0 0 0 2 0]\n",
      " [0 0 0 1 0 0 0 0 0 1 1 0 0 1 2 0]]\n"
     ]
    }
   ],
   "source": [
    "#calculate term frequencies\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,\\\n",
    "TfidfTransformer\n",
    "\n",
    "docs = [\"the house had a tiny little mouse\",\n",
    "      \"the cat saw the mouse\",\n",
    "      \"the mouse ran away from the house\",\n",
    "      \"the cat finally ate the mouse\",\n",
    "      \"the end of the mouse story\"\n",
    "     ]\n",
    "\n",
    "#calculate term frequencies\n",
    "\n",
    "vectorizer = CountVectorizer ()\n",
    "vectorizer.fit (docs) #learn the vocabulary\n",
    "print (vectorizer.vocabulary_)\n",
    "print (vectorizer.get_feature_names ())\n",
    "#return a 'document term matrix' having tf's (count of tokens)\n",
    "word_count_vector = vectorizer.fit_transform (docs)\n",
    "#print (word_count_vector)\n",
    "print (word_count_vector.toarray ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vector Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverse document frequencies using TfidfTransformer's fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Note:</font>\n",
    "- For IDF, the log is to the __base 'e'__.\n",
    "- __+1__ on IDF to prevent it from becoming 0 for cases where a word is found in all documents.\n",
    "    - so, an idf value of __1.91__ is __actually 0.91 (ln(5/2))__\n",
    "        - The word 'cat' appears in 2 out of 5 documents. So, its idf is ln(5/2) = 0.91 bumped up to 1.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.60943791 2.60943791 1.91629073 2.60943791 2.60943791 2.60943791\n",
      " 2.60943791 1.91629073 2.60943791 1.         2.60943791 2.60943791\n",
      " 2.60943791 2.60943791 1.         2.60943791]\n"
     ]
    }
   ],
   "source": [
    "#calculate inverse-document frequencies\n",
    "\n",
    "transformer = TfidfTransformer (norm=None, smooth_idf=False)\n",
    "idf = transformer.fit (word_count_vector)\n",
    "print (idf.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf using TfidfTransformer's transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  2.60943791 1.91629073 2.60943791 1.         0.         0.\n",
      "  0.         0.         1.         2.60943791]\n",
      " [0.         0.         1.91629073 0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  2.60943791 0.         2.         0.        ]\n",
      " [0.         2.60943791 0.         0.         0.         2.60943791\n",
      "  0.         1.91629073 0.         1.         0.         2.60943791\n",
      "  0.         0.         2.         0.        ]\n",
      " [2.60943791 0.         1.91629073 0.         2.60943791 0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         2.         0.        ]\n",
      " [0.         0.         0.         2.60943791 0.         0.\n",
      "  0.         0.         0.         1.         2.60943791 0.\n",
      "  0.         2.60943791 2.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#calculate term-document-inverse-document frequencies\n",
    "\n",
    "#transformer = TfidfTransformer ()\n",
    "tf_idf = transformer.transform (word_count_vector)\n",
    "print (tf_idf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurrence Vector Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction-based embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
